{
  "level": "Graduate",
  "topics": [
    [
      "Mathematics",
      "Probability and Statistics"
    ],
    [
      "Science",
      "Cognitive Science"
    ]
  ],
  "instructors": {
    "content": [
      "5f6bd7a0-06b9-c3c4-8759-e6aab3545d24",
      "e6064030-8ace-6529-06a3-39a293ce552e"
    ],
    "website": "ocw-www"
  },
  "course_title": "Networks for Learning: Regression and Classification",
  "course_description": "The course focuses on the problem of supervised learning within the framework of Statistical Learning Theory. It starts with a review of classical statistical techniques, including Regularization Theory in RKHS for multivariate function approximation from sparse data. Next, VC theory is discussed in detail and used to justify classification and regression techniques such as Regularization Networks and Support Vector Machines. Selected topics such as boosting, feature selection and multiclass classification will complete the theory part of the course. During the course we will examine applications of several learning techniques in areas such as computer vision, computer graphics, database search and time-series analysis and prediction. We will briefly discuss implications of learning theories for how the brain may learn from experience, focusing on the neurobiology of object recognition. We plan to emphasize hands-on applications and exercises, paralleling the rapidly increasing practical uses of the techniques described in the subject.\n",
  "department_numbers": [
    "9"
  ],
  "extra_course_numbers": "",
  "primary_course_number": "9.520-A",
  "learning_resource_types": [
    "Problem Sets",
    "Written Assignments"
  ],
  "title": "Course Metadata"
}